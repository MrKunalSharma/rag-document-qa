
---
title: RAG Document QA
emoji: ğŸ“š
colorFrom: purple
colorTo: red
sdk: streamlit
sdk_version: "1.28.1"
app_file: app.py
pinned: false
---

# ğŸ“š RAG Document Q&A System

A production-ready Retrieval-Augmented Generation (RAG) system that enables intelligent question-answering over PDF documents using semantic search and natural language processing.

![Python](https://img.shields.io/badge/python-v3.9+-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.104.0-green.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-1.28.0-red.svg)
![License](https://img.shields.io/badge/license-MIT-blue.svg)

ğŸ”— **[Live Demo](https://rag-document-app-n9nrripappuptgnnafem92v.streamlit.app/)** 

## ğŸŒŸ Features

- **ğŸ” Semantic Search**: Find relevant information using natural language queries, not just keywords
- **ğŸ“„ Multi-Document Support**: Process and search across multiple PDF files simultaneously
- **âš¡ Real-time Processing**: Sub-second query response times with efficient vector search
- **ğŸ¯ Dual Mode Operation**: Works with or without OpenAI API for flexibility
- **ğŸš€ RESTful API**: Well-documented API endpoints for easy integration
- **ğŸ’¾ Persistent Storage**: ChromaDB vector database with 425+ indexed document chunks
- **ğŸ¨ Interactive UI**: Beautiful Streamlit interface with real-time results

## ğŸ—ï¸ Architecture



                
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â”‚ â”‚ â”‚ â”‚ â”‚
â”‚ Streamlit UI â”‚â”€â”€â”€â”€â–¶â”‚ FastAPI â”‚â”€â”€â”€â”€â–¶â”‚ ChromaDB â”‚
â”‚ (Frontend) â”‚ â”‚ (Backend) â”‚ â”‚ (Vector Store) â”‚
â”‚ â”‚ â”‚ â”‚ â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â”‚
â”‚ LangChain Pipeline â”‚
â”‚ - Document Processing â”‚
â”‚ - Embeddings (HF) â”‚
â”‚ - RAG Chain â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜




## ğŸš€ Live Demo

ğŸ”— **[Try the Live Demo Here](https://rag-document-app-n9nrripappuptgnnafem92v.streamlit.app/)**

### Demo Features:
- Interactive search interface
- Sample questions for quick testing
- File upload demonstration
- Performance analytics
- Technical architecture details

## ğŸ“Š Performance Metrics

| Metric | Value | Description |
|--------|-------|-------------|
| **Query Response Time** | < 1 second | End-to-end search latency |
| **Document Chunks** | 425+ | Searchable text segments |
| **Embedding Dimensions** | 384 | Using all-MiniLM-L6-v2 |
| **Similarity Accuracy** | 87.8% | Relevance score threshold |
| **Chunk Size** | 1000 chars | Optimal context preservation |
| **Chunk Overlap** | 200 chars | Ensures continuity |

## ğŸ› ï¸ Tech Stack

- **Backend**: FastAPI, LangChain, ChromaDB
- **Frontend**: Streamlit
- **ML/AI**: Sentence Transformers, HuggingFace Embeddings
- **Storage**: ChromaDB (Persistent Vector Store)
- **Processing**: PyPDF for document extraction
- **Optional**: OpenAI API for enhanced generation

## ğŸ“‹ Prerequisites

- Python 3.9 or higher
- pip package manager
- (Optional) OpenAI API key for full RAG functionality

## ğŸ› ï¸ Installation

1. **Clone the repository:**
```bash
git clone https://github.com/MrKunalSharma/rag-document-qa.git
cd rag-document-qa/rag-document-qa


          
Create virtual environment:

          

bash


python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate


                
Install dependencies:

          

bash


pip install -r requirements.txt


                
Set up environment variables (optional):

          

bash


# Create .env file
echo "OPENAI_API_KEY=your_key_here" > .env


                
ğŸƒâ€â™‚ï¸ Running the Complete System
Start the Backend API:

          

bash


python src/api/main.py


                
The API will be available at http://localhost:8000

Start the Frontend (new terminal):

          

bash


streamlit run src/frontend/app.py


                
Access the UI at http://localhost:8501

ğŸ“š Project Structure



rag-document-qa/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # Original PDF documents
â”‚   â””â”€â”€ chromadb/           # Vector database (425+ chunks)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ main.py         # FastAPI backend server
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ document_processor.py  # PDF processing pipeline
â”‚   â”‚   â”œâ”€â”€ rag_chain.py          # RAG orchestration
â”‚   â”‚   â””â”€â”€ vector_store.py       # ChromaDB integration
â”‚   â””â”€â”€ frontend/
â”‚       â””â”€â”€ app.py          # Streamlit UI
â”œâ”€â”€ requirements.txt        # Project dependencies
â”œâ”€â”€ .env.example           # Environment variables template
â””â”€â”€ README.md             # This file


          
ğŸ“ API Documentation
Health Check

          

http


GET /health


                
Search Endpoint (No LLM Required)

          

http


POST /search
Content-Type: application/json

{
    "question": "How does self-attention work?",
    "num_results": 5
}


                
Query Endpoint (Full RAG with Optional LLM)

          

http


POST /query
Content-Type: application/json

{
    "question": "Explain the transformer architecture",
    "num_results": 3
}


                
Response Format

          

json


{
    "question": "How does self-attention work?",
    "answer": "Based on the search results...",
    "sources": [
        {
            "source": "attention_is_all_you_need.pdf",
            "content": "Self-attention is an attention mechanism...",
            "score": "0.878"
        }
    ]
}


                
ğŸ”§ Configuration
Parameter	Default	Description
chunk_size	1000	Characters per chunk
chunk_overlap	200	Overlap between chunks
embedding_model	all-MiniLM-L6-v2	HuggingFace model
vector_dimensions	384	Embedding dimensions
similarity_metric	cosine	Distance calculation
ğŸ¯ Use Cases
ğŸ“š Academic Research: Search through research papers and citations
âš–ï¸ Legal Documentation: Find relevant cases and precedents
ğŸ¥ Healthcare: Search medical literature and patient records
ğŸ¢ Enterprise Knowledge Base: Internal documentation search
ğŸ“– Educational Content: Smart library and course material search
ğŸš€ Future Enhancements
[ ] Multi-language support
[ ] GPU acceleration for embeddings
[ ] Real-time document upload via API
[ ] Advanced filtering options
[ ] Export results to various formats
[ ] User authentication and management
ğŸ¤ Contributing
Contributions are welcome! Please feel free to submit a Pull Request.

Fork the repository
Create your feature branch (git checkout -b feature/AmazingFeature)
Commit your changes (git commit -m 'Add some AmazingFeature')
Push to the branch (git push origin feature/AmazingFeature)
Open a Pull Request
ğŸ“ License
This project is licensed under the MIT License - see the LICENSE file for details.

ğŸ‘¨â€ğŸ’» Author
Kunal Sharma

ğŸ”— GitHub: [@MrKunalSharma](https://github.com/MrKunalSharma/rag-document-qa)
ğŸ’¼ LinkedIn: [Kunal Sharma](https://www.linkedin.com/in/kunal-sharma-1a8457257/)
ğŸ“§ Email: kunalsharma13579kunals@gmail.com
ğŸ™ Acknowledgments
LangChain for the excellent RAG framework
Sentence Transformers team for the embedding models
ChromaDB for the vector database
Streamlit for the amazing UI framework
<p align="center">
Built with â¤ï¸ for the AI community
<br>
â­ Star this repo if you find it helpful!
</p>


